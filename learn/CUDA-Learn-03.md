# CUDA编程学习笔记-03

### 0  前言

前面的一节中谈到了CUDA的执行模型，也就是什么样的线程组织结构能让核函数跑的更快，但程序的运行效率除了线程结构以外，内存的读写也是一个很重要的决定性因素，就如同谭升在博客中类比的一个故事：工厂生产，我们可以通过优化工厂内部流水线，工人分配，工人质量，来提高生产速度，但是如果你把工厂开到珠穆朗玛峰顶，工厂在生产时所需要的原材料都需要费好大的劲 运到山顶，那么整体而言，工厂的生产效率就非常低，即使你工厂内部的流水线效率很高，但也架不住做完一份原材料都需要等一年(假设原材料上山的时间)才能等到下一份原材料。这个例子中，工厂生产我们就可以理解为核函数运行，内部的工人分配可以理解为线程组织结构，而原材料上下山可以理解为内存的读写，所以很显然这些问题都在决定着程序运行的效率。

本节就主要从内存管理角度出发谈一谈内存管理对CUDA 程序运行的影响～

> 暗搓搓的吐槽一下

### 1  内存模型

![memory_level](CUDA-Learn-03md.assets/memory_level.png)

如上图所示，为现代计算机普遍采用的内存结构示意图，从上至下依次为，寄存器(Registers)、缓存(Caches)、主存(Main Memory)和磁盘(Disk Memory)，其中它们的读写速度逐渐降低，存储容量逐渐增大。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想～

#### 1.1 CUDA内存模型

CUDA内存模型提出了多种可编程内存的类型：

* 寄存器(Registers)
* 共享内存(Shared memory)
* 本地内存(Local memory)
* 常量内存(Constant memory)
* 纹理内存(Texture memory)
* 全局内存(Global memory)

![avatar](CUDA-Learn-03md.assets/cuda-memory.png)

如上图为这些内存空间的层次结构，每种都有不同的作用域、生命周期和缓存行为。核函数中的每个线程都有自己私有的本地内存(Local memory)；每个线程块都有自己的共享内存，这个共享内存(Shared memory)对同一线程块中所有的线程都可见；所有线程都能访问全局内存(Global memory)，所有线程都能访问的只读空间有：常量内存空间和纹理内存空间。

##### 1.1.1 寄存器

寄存器无论是在CPU还是在GPU都是速度最快的内存空间，但是和CPU不同的是**GPU的寄存器储量要多一些**，而且当我们**在核函数内不加修饰的声明一个变量，此变量就存储在寄存器中**，但是CPU运行的程序有些不同，只有当前在计算的变量存储在寄存器中，其余在主存中，使用时传输至寄存器。在核函数中定义的有常数长度的数组也是在寄存器中分配地址的。
寄存器对于每个线程是私有的，寄存器通常保存被频繁使用的私有变量，注意这里的变量也一定不能使共有的，不然的话彼此之间不可见，就会导致大家同时改变一个变量而互相不知道，寄存器变量的声明周期和核函数一致，从开始运行到运行结束，执行完毕后，寄存器就不能访问了。

在不同架构的GPU中，每个线程最多拥有的寄存器数量是有限的，如果一个核函数使用了超过限制的寄存器数量，那么就会用本地内存来帮忙，这称之为**寄存器溢出**，这会对性能带来不利影响。我们可以在代码中显式的加上如上额外信息来帮助编译器进行优化：

```cpp
__global__ void
__lauch_bounds__(maxThreadaPerBlock,minBlocksPerMultiprocessor)
kernel(...) {
    /* kernel code */
}
```

其中

##### 1.1.2 本地内存



##### 1.1.3 共享内存

在核函数中使用如下修饰符的内存，称之为共享内存：

```c++
__share__ 
```

* 每个SM都有一定数量的由线程块分配的共享内存，**共享内存是片上内存**，跟主存相比，速度要快很多，也即是延迟低，带宽高。其类似于一级缓存，但是可以被编程。

* 使用共享内存的时候一定要注意，**不要因为过度使用共享内存**，而导致SM上活跃的线程束减少，也就是说，**一个线程块使用的共享内存过多，导致更过的线程块没办法被SM启动，这样影响活跃的线程束数量。**

* 共享内存是线程之间相互通信的基本方式，但正因为共享内存在线程块内都可见，所以要避免内存竞争，可以通过如下同步语句：

  ```c++
  void __syncthreads();
  //这个函数设立了一个执行障碍点，即同一个线程块中的所有线程到这里就同步了
  //注意：__syncthreads 频繁使用会影响内核执行效率。
  ```



##### 1.1.4 常量内存

常量内存驻留在设备内存中，并在每个SM专用的常量缓存中缓存。常量变量用如下修饰符修饰：

```c++
__constant__
```

* 常量内存必须在**全局空间内和所有核函数之外进行声明**

* 核函数只能从常量内存中读取数据，因此，常量内存必须在**主机端**使用如下函数来初始化：

  ```c++
  cudaError_t cudaMemcpyToSymbol(const void* symbol, const void* src, size_t count)
  //函数功能：从src指向的count个字节复制到symbol指向的内存中，也就是设备的常量内存
  ```

* 线程束中的所有线程从相同的地址读取数据是，常量内存表现最好；但如果线程束里每个线程都从不同的地址空间读取数据，常量内存中就不是最佳选择，因为**每从一个常量内存中读取一次数据，都会广播给线程束里的所有线程**

##### 1.1.5 纹理内存

略

##### 1.1.6 全局内存

GPU上最大的内存空间，延迟最高，使用最常见的内存，比如咱们常说的8G 的1080 显卡的就是说的这个内存。

一个全局内存变量可以被静态声明或动态声明。动态声明就是前面讲过的`cudaMalloc`的方式，静态全局内存要使用`__device__`来修饰，如下为静态全局内存的使用示例

```c++
#include <cuda_runtime.h>
#include <stdio.h>
//定义的静态全局变量
__device__ float devData;
__global__ void checkGlobalVariable()
{
    printf("Device: The value of the global variable is %f\n",devData);
    devData+=2.0;
}
int main()
{
    float value=3.14f;
    //这里注意,
    cudaMemcpyToSymbol(devData,&value,sizeof(float));
    printf("Host: copy %f to the global variable\n",value);
    checkGlobalVariable<<<1,1>>>();
    cudaMemcpyFromSymbol(&value,devData,sizeof(float));
    printf("Host: the value changed by the kernel to %f \n",value);
    cudaDeviceReset();
    return EXIT_SUCCESS;
}
```

![avatar](CUDA-Learn-03md.assets/global-mem.png)

关于上述代码需要注意的几点：

1. 在主机端，devData只是一个在GPU上表示物理位置的标识符，不是设备全局内存的变量地址。所以不能对其使用"&"
2. 在核函数中，devData就是一个全局内存中的变量。
3. 主机代码不能直接访问设备变量，设备也不能访问主机变量



#### 1.2 CUDA内存小结

| 修饰符         | 变量名称       | 存储器 | 作用域 | 生命周期 |
| -------------- | -------------- | ------ | ------ | -------- |
|                | float var      | 寄存器 | 线程   | 线程     |
|                | float var[100] | 本地   | 线程   | 线程     |
| __ share __    | float var*     | 共享   | 块     | 块       |
| __ device __   | float var*     | 全局   | 全局   | 应用程序 |
| __ constant __ | float var*     | 常量   | 全局   | 应用程序 |

*表示既可以为标量也可以为数组

| 存储器 | 片上/片外 |   缓存    | 存取 |     范围      | 生命周期 |
| :----: | :-------: | :-------: | :--: | :-----------: | :------: |
| 寄存器 |   片上    |    n/a    | R/W  |   一个线程    |   线程   |
|  本地  |   片外    | 1.0以上有 | R/W  |   一个线程    |   线程   |
|  共享  |   片上    |    n/a    | R/W  | 块内所有线程  |    块    |
|  全局  |   片外    | 1.0以上有 | R/W  | 所有线程+主机 | 主机配置 |
|  常量  |   片外    |    Yes    |  R   | 所有线程+主机 | 主机配置 |
|  纹理  |   片外    |    Yes    |  R   | 所有线程+主机 | 主机配置 |

### 2 内存管理

一般使用`cudaMemcpy`进行内存传输，设备端使用`cudaMalloc`分配内存

固定内存：使用`malloc`分配的内存默认是可分页的，
